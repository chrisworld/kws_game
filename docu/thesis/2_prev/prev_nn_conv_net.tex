% --
% prev convolutional nets

\subsection{Convolutional Neural Networks}\label{sec:prev_nn_cnn}
Convolutional Neural Networks (CNNs) are a class of neural networks, that are able to incorporate spatial information with the application of convolutional filtering to create feature maps.
Spatial information is very important in images, where neighboring pixels are related to each other.
The same holds for audio, but in only one dimension and with a higher amount of samples.
Convolutional filters are very commonly applied in image processing tasks, such as denoising or other enhancement of images.
In audio processing, a classical application of convolutional filters is a simple average filter of the signals energy, to determine onsets like the start of a speech signal.

Still it took relatively long till convolutional filters were a common and wide used asset in neural network architectures.
The general concepts of CNNs with feature maps (outputs of applied convolutional filters) and weight sharing through convolutional filters, were examined by LeCun et. al. on handwritten postal codes in 1989 \cite{LeCun1989_Generalization}.
Further research and experiments on the famous MNIST dataset of handwritten digits, were done in the late 90s \cite{LeCun1998} and asserted the success of CNNs.
A classical convolutional layer in CNNs usually consists of multiple convolutional filters with trainable weights and additive bias terms per filter, followed by a non-linear activation function to calculate outputs in a feature map.
%Since then many famous image recognition models were introduced that incorporated CNNs and achieved state of the art performances.

%This is one reason why CNNs are so practicable for image recognition tasks and usually state of the art image recognition architectures have some kind of convolutional neural network implemented within.

%With their restricted and highly spatial connections and weight sharing through convolutional filters, they are an valuable asset no researchers should miss when working with images or audio recognition.

  
% best quote ever
%It is trivial to design a machine that learns very quickly, does not generalize, and requires an enormous amount of hardware. 
%In fact this learning machine has already been built and is called a Random Access Memory.
