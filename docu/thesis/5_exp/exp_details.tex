% --
% training details

\section{Implementation and Training Details}\label{sec:exp_details}
\thesisStateNotReady
In this sections, the implementation und parameters for training are is described in more detail.

% --
% implementation notes

\subsection{Implementation notes}\label{sec:exp_details_implementation}
The programming code for this thesis was entirely done in \texttt{Python} with version $>3.8$ evaluated on a linux system.
This might be important if one tries to run the python code on a windows machine, it was not tested for it and could yield in errors (especially regarding paths variables).
For the neural networks implementation and training, the framework \texttt{Pytorch} with version $1.7.0$ was used. 
Usually it should not be a problem if a newer version of \texttt{Pytorch} is applied.
The feature extraction with Mel Frequency Cepstral Coefficients (MFCC) was done with an own implementation, but using efficients functions for transforms functions, such as the short time fourier transform, with packages from \texttt{scipy}.
Matrix computations usually are done with the package \texttt{numpy}.
Several other \texttt{Python} packages were used within the project, but are not named explicitly.

% --
% training details

\subsection{Neural Network Training Details}\label{sec:exp_details_training}
The training details of neural networks can be split into following parameters:
\begin{enumerate}
  \item Features extraction parameters
  \item Dataset parameters
  \item Feature selection
  \item Transfer Learning parameters
  \item Training parameters
\end{enumerate}
The feature extraction parameters provide information about how the features were extracted, such as the hop size, frame size, filter bands of the MFCC, etc.
The dataset parameters provides the selected labels, how many examples per labels are used and the feature selection of the extracted MFCCs. 
%The Abbreviation regarding dataset parameters and feature selection were already listed in \rtab{exp_dataset_abbr}.
%The feature selection is the information about what input feature groups are used in the training, e.g. use cepstral coefficients only, or add delta and energy features, their references are shown in \rtab{dataset_feature_groups}.
The transfer learning parameters are details about how the pre-trained weights from adversarial pre-training is used for the actual neural network architecture.
For instance it describes if the weights are used from the discriminator or generator network or how much epochs were used for the adversarial training, etc.
%The Abbreviations for training parameters can be specified as listed in \rtab{exp_details_adv}
%\input{./5_exp/tables/tab_exp_details_adv.tex}

The training parameters are the parameters used for neural network training, such as learning rate, number of epochs, etc.
%Their selection and references are listed in \rtab{exp_details_train_params}
%\input{./5_exp/tables/tab_exp_details_train_params.tex}

