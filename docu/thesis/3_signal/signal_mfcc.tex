% --
% mfcc

\section{Mel Frequency Cepstral Coefficients}\label{sec:signal_mfcc}
Most commonly the Mel Frequency Cepstral Coefficients (MFCC) are used as input features for neural network classifications tasks of audio data.
It is described why they are good features and how they can be visualized to understand them better.

\begin{figure}[!ht]
  \centering
    \subfigure[left]{\includegraphics[width=0.45\textwidth]{./3_signal/figs/signal_mfcc_left0_my}}
    \subfigure[right]{\includegraphics[width=0.45\textwidth]{./3_signal/figs/signal_mfcc_right0_my}}
    \subfigure[up]{\includegraphics[width=0.45\textwidth]{./3_signal/figs/signal_mfcc_up0_my}}
    \subfigure[down]{\includegraphics[width=0.45\textwidth]{./3_signal/figs/signal_mfcc_down0_my}}
    \subfigure[go]{\includegraphics[width=0.45\textwidth]{./3_signal/figs/signal_mfcc_go0_my}}
  \caption{MFCC visualized with frame-based normalization.}
  \label{fig:signal_mfcc_examples}
\end{figure}
\FloatBarrier
\noindent

\subsection{The Idea behind}
To comprehend the success and wide use of MFCCs features in neural networks and other machine learning applications, it is necessary to understand its processing scheme:
Raw audio samples are transformed into the frequency domain with the Short-Time Fourier Transform (STFT).
Afterwards the power spectrum of the STFT is segmented in frequency bands (along the frequency dimension) done by a filter bank.
The filter bands are spaced in equidistant mel frequencies,
where the term mel frequencies is referred to the non-linear relationship between the mel and frequency scale.
The mel scale was developed in psycho-acoustic experiments, where researchers found out, that high frequency sounds are perceived lower by humans, than they actual are (in musical hearing). For instance, in the musical sense an octave is the doubling of the frequency, but for human hearing it is strongly different and frequency doubling is not enough so that the same pitch is perceived.
This effect usually becomes imminent over \SI{500}{\hertz}.
As conclusion the mel scale is suited human hearing perception and taking equidistant mel bands is a reasonable decision.
In the following a logarithmic scaling in the value space of the power spectrum is done, which is also related to human hearing.
The last step is not that straight forward, but is a technique widely used in image processing, called the Discrete Cosine Transform (DCT).
It is only to mention that is some kind of decorrelation process, so that different filter bands are mixed together.

This processing steps seem rather complicated in the beginning, but are in fact nothing else but consecutive steps of appropriate scaling and data compression.
It is to mention that neural networks usually are able to handle large amounts of input features, but it is always preferable to decrease the input size, such that the model size of the neural network can be decreased same-wise.
Therefore it becomes more clear, why frequencies are put into certain frequency bands, are log scaled and as last step decorrelated with a method like the DCT.

\subsection{Processing Pipeline in detail}
The frequency spectrum is spitted into filter bands, done by triangular window functions.
Those window functions must have a fixed length on the mel space (equidistant mel bands), that results in different spacing in
the frequency space.
The mel - frequency relation can be approximated with:
\begin{equation}\label{eq:signal_mfcc_mel}
  m(f) = 2595 \cdot \log_{10} \left(1 + \frac{f}{700} \right) 
\end{equation}
where $m$ is the result in mel scale as function of the frequency $f$.
The mel scale plotted against the frequency scale is illustrated in \rfig{signal_mfcc_mel_scale}
\begin{figure}[!ht]
  \centering
  \includegraphics[width=0.40\textwidth]{./3_signal/figs/signal_mfcc_mel_scale}
  \caption{Mel scale as function of the frequency in a range of [0, \SI{16}{\kilo\hertz}].}
  \label{fig:signal_mfcc_mel_scale}
\end{figure}
\FloatBarrier
\noindent


The mel and frequency window functions are shown in \rfig{filter_bands}.
\begin{figure}[!ht]
  \centering
  \subfigure[mel space]{\includegraphics[width=0.40\textwidth]{./3_signal/figs/signal_mfcc_weights_mel}}
  \quad
  \subfigure[frequency space]{\includegraphics[width=0.40\textwidth]{./3_signal/figs/signal_mfcc_weights_f}}
  \caption{Equidistant mel filter bands with a total number of 32 bands.}
  \label{fig:filter_bands}
\end{figure}
\FloatBarrier
\noindent

The DCT is similar to the Fourier Transform and projects the input signal to a set of basis functions, with following general calculation for the type 2 DCT:

% dct
\begin{equation}\label{eq:signal_mfcc_dct}
  X[k] = \sum_{n=0}^{N-1} x[n] \, \cos{\left[ \frac{\pi}{N} \left( n + \frac{1}{2} \right) k  \right]}
\end{equation}
or conveniently with matrix notation basis functions:
\begin{equation}\label{eq:signal_mfcc_dct_matrix}
  X[k] = D \, x[n] \quad \mathrm{with} \quad D[n, k] = \cos{\left[ \frac{\pi}{N} \left( n + \frac{1}{2} \right) k  \right]}, \quad n, k = 0 \dots N - 1
\end{equation}

These Basis functions are illustrated in \rfig{signal_mfcc_dct}
\begin{figure}[!ht]
  \centering
  \subfigure[DCT with continuous color scheme]{\includegraphics[width=0.40\textwidth]{./3_signal/figs/signal_mfcc_dct}}
  \quad
  \subfigure[DCT with diverging color scheme]{\includegraphics[width=0.40\textwidth]{./3_signal/figs/signal_mfcc_dct-div}}
  \caption{DCT matrix with 32 basis functions illustrated with a continuous and a diverging color scheme.}
  \label{fig:signal_mfcc_dct}
\end{figure}
\FloatBarrier
\noindent


\subsection{MFCC Feature Usage and Enhancement}
After the MFCCs are computed, they can be used as input features for neural networks. 
The important Question here is whether an feature enhancement can be done and if all those computed features are necessarily and meaningful for the training and evaluation success of neural networks. Usually not all MFCC coefficients are used as inputs, this is merely done to reduce the computational cost in case the accuracy does not suffer from it.
A good application is to compute 32 MFCC features (with 32 equidistant Mel filter bands) and use only the first 12 of them as inputs.
Further it is also possible to compute derivatives (in the time domain) of MFCC features, denoted as Deltas. 
Those derivatives are simple computed as frame difference of the MFCCs.
A second derivative of MFCC features, known as Double Deltas, are then the frame differences of the Deltas.
An energy feature can be computed from each of the MFCCs, Deltas and Double Deltas, each by its own and added to the feature vectors.
Those feature vectors can then be simply stacked at top of each other and used as feature inputs.
In this thesis the feature vectors are stacked as following:
\begin{enumerate}
    \item 12 MFCCs
    \item 1 Energy feature of the 12 MFCCs
    \item 12 Deltas
    \item 1 Energy feature of the 12 Deltas
    \item 12 Double Deltas
    \item 1 Energy feature of the 12 Double Deltas
\end{enumerate}
Which sums up to a 39-dimensional feature vector.

\subsection{Visualisation of MFCC features}
A good visualisation of MFCC features is necessary to observe the difference between different spoken words.
MFCCs computed in their traditional way, are not well intended for visualisations, since their individual coefficients value space differs strongly from each other.
For example, the first coefficient equals a summation of all filter bands of the spectrogram and is therefore some kind of energy measure, while the other coefficients are weighted sum combinations of the filter bands.
This forms a totally different value spaces between the individual coefficients and since their value should be represented with colors in linear scale, the visualization cannot show the important structure that is given by the MFCCs.
Further the most of the signal energy is located in the lower frequency bands, which also impacts the value space of the individual coefficients.

%To show this difference in value space in a negative example in practice, the MFCCs of the self-recorded speech command waveform \enquote{left0.wav} is shown in \rfig{left0_mfcc_only}.
% useless
% \begin{figure}[!ht]
%   \centering
%     \includegraphics[width=0.75\textwidth]{./3_signal/figs/signal_mfcc_left0_mfcc_only.png}
%   \caption{Bad visualisation of the 12 MFCCs features extracted from \enquote{left0.wav}.}
%   \label{fig:left0_mfcc_only}
% \end{figure}
% \FloatBarrier
% \noindent
% Not much structure of the MFCCs can be seen here, due to the vast value difference of the first coefficient. At least the first coefficient shows, where the center of signal energy is placed on the time scale, but other than that, this visualisation is worthless.
% Another very bad visualisation is shown by computing the 39 MFCC feature vectors (with Deltas, Double Deltas and Energies) in \rfig{left0_no_order}.

% \begin{figure}[!ht]
%   \centering
%     \includegraphics[width=0.75\textwidth]{./3_signal/figs/signal_mfcc_left0_no_order_norm0.png}
%   \caption{Very bad visualisation of 39 MFCC features extracted from \enquote{left0.wav}.}
%   \label{fig:left0_no_order}
% \end{figure}
% \FloatBarrier
% \noindent
% There appears an even greater gap of different value spaces and even less is seen.

One solution is to show the features in different value groups. 
For instance putting the first coefficient and its deltas is in one group, the other coefficients in another and their deltas and energies as well in own groups. 
Now it is possible to observe some structure in the visualisations, with an example shown in \rfig{left0_order}.

\begin{figure}[!ht]
  \centering
    \includegraphics[width=0.75\textwidth]{./3_signal/figs/signal_mfcc_left0_norm0.png}
  \caption{Good visualisation of 39 MFCC features extracted from \enquote{left0.wav} with own value groupings.}
  \label{fig:left0_order}
\end{figure}
\FloatBarrier
\noindent
Another way to improve the visualisation is to normalize the feature vectors over each frame dimension with the infinity norm as:

% frame normalisation
\begin{equation}\label{eq:signal_mfcc_norm}
  \hat{U}[m, l] = \frac{U[m, l]}{\norm{u_l[m]}_\infty}
\end{equation}
where $m$ is again the variable in frames, $l$ the individual MFCC coefficient and $u_l[m]$ the individual MFCC coefficient vector over all frames.
This equation gives a value space between $[0, 1]$ for each feature vector $u_l[m]$.

A visualisation with frame normalisation of the 39 MFCC feature vectors of \enquote{left0.wav} is shown in \rfig{left0_order},

\begin{figure}[!ht]
  \centering
    \includegraphics[width=0.75\textwidth]{./3_signal/figs/signal_mfcc_left0_no_order_norm1.png}
  \caption{Normalisation of 39 MFCC features extracted from \enquote{left0.wav}.}
  \label{fig:left0_no_order_norm1}
\end{figure}
\FloatBarrier
\noindent
or in an even better one shown in \rfig{left0_order_norm1}.

\begin{figure}[!ht]
  \centering
    \includegraphics[width=0.75\textwidth]{./3_signal/figs/signal_mfcc_left0_order_norm1.png}
  \caption{Normalisation of 39 MFCC features extracted from \enquote{left0.wav} with groups.}
  \label{fig:left0_order_norm1}
\end{figure}
\FloatBarrier
\noindent
As conclusion, the normalisation in the frame space is an interesting aspect to improve the visualisation of the MFCC features, 
specifically for the cepstral coefficients and the energy features (not the deltas).
Exactly this nice representation was motivating to explore normalisation of feature for neural network inputs.
However this is a very crucial thing to do. A normalisation relatives important structures within the feature space and it cannot really be answered if this is a good thing or not.
One more research question arises here: Is it possible to use normalisation for the features as inputs to neural networks and what are the results to the accuracy and training of the models.
