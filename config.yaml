# --
# config file for this project

# --
# general stuff

config_changer_allowed: False


# --
# dataset config

datasets:

  # --
  # version description
  # 1: better onset detection
  # 2: energy frame onset detection
  # 3: data extraction with min energy and randomize onsets
  # 4: normalized features
  # 5: no energy features, detection on first mfcc, dataset shuffled

  # speech commands dataset
  speech_commands:

    # file extension for audio files
    file_ext: '.wav'

    # number of samples
    sample_num_normal: 16000
    sample_num_mininmal: 8000

    # path to speech command dataset
    dataset_path: ignore/dataset/speech_commands_v0.01/
    #dataset_path: ignore/dataset/speech_commands_v0.02/

    # shuffle wavs for dataset separation
    shuffle_wavs: True

    # extraction path
    extraction_path: ignore/dataset/extracted/

    # paths to save training, testing and eval data
    data_paths:
      # train: ignore/dataset/train/
      # test: ignore/dataset/test/
      # eval: ignore/dataset/eval/
      train: train/
      test: test/
      eval: eval/

    # folder names
    wav_folder: wavs/
    annotation_folder: annotation/

    # split of dataset in training, test, eval (must be a prob. distribution)
    split_percs: [0.8, 0.1, 0.1]

    # plot path root
    plot_paths:
      mfcc: ignore/dataset/plots/mfcc/
      z_score: ignore/dataset/plots/z_score/
      waveform: ignore/dataset/plots/waveform/
      examples_grid: ignore/dataset/plots/
      damaged_files: ignore/dataset/damaged_files/

    # enable plot of each feature extraction
    enable_plot: False

    # recreate all datasets (copy wavs to data_paths - not necessary except the dataset is changed)
    recreate: True

    # selected labels of the whole set
    sel_labels: ['left', 'right', 'up', 'down', 'go']
    #sel_labels: ['yes', 'no', 'left', 'go', 'down', 'off', 'right', 'stop', 'up', 'on']
    #sel_labels: ['eight', 'sheila', 'nine', 'yes', 'one', 'no', 'left', 'tree', 'bed', 'bird', 'go', 'wow', 'seven', 'marvin', 'dog', 'three', 'two', 'house', 'down', 'six', 'five', 'off', 'right', 'cat', 'zero', 'four', 'stop', 'up', 'on', 'happy']

    # add noise to dataset
    add_noise: True
    noise_label: noise
    noise_data_folder: _background_noise_/

    # version
    version_nr: 5

    # number of examples picked from dataset
    #n_examples: 10
    n_examples: 500
    #n_examples: 2000

    # file name for saved feature files
    mfcc_feature_file_name: mfcc_data
    raw_feature_file_name: raw_data

    # filter damaged files
    filter_damaged_files: False


  # my recordings dataset
  my_recordings:

    # file extension for audio files
    file_ext: '.wav'

    # number of samples
    sample_num_normal: 16000
    sample_num_mininmal: 8000

    # path to speech command dataset
    dataset_path: ignore/dataset/my_recordings/

    # shuffle wavs for dataset separation
    shuffle_wavs: False

    # extraction path
    extraction_path: ignore/dataset/extracted/

    # paths to save training, testing and eval data
    data_paths:
      my: my/

    # folder names
    wav_folder: wavs/
    annotation_folder: annotation/

    # split of dataset
    split_percs: [1.0]

    # plot path root
    plot_paths:
      mfcc: ignore/my_recordings/plots/mfcc/
      z_score: ignore/my_recordings/plots/z_score/
      onsets: ignore/my_recordings/plots/onsets/
      waveform: ignore/my_recordings/plots/waveform/
      examples_grid: ignore/my_recordings/plots/

    # enable plot of each feature extraction
    enable_plot: False

    # recreate all datasets (copy wavs to data_paths - not necessary except the dataset is changed)
    recreate: False

    # selected labels of the whole set
    sel_labels: ['left', 'right', 'up', 'down', 'go']

    # add noise to dataset
    add_noise: True
    noise_label: 'noise'
    
    #version
    version_nr: 5

    # number of examples picked from dataset
    n_examples: 5

    # file name for saved feature files
    mfcc_feature_file_name: mfcc_data_my
    raw_feature_file_name: raw_data_my

    # filter damaged files
    filter_damaged_files: False


# --
# feature params for dataset extraction

feature_params:

  # mfcc_features or raw samples
  use_mfcc_features: True

  # sampling rate
  fs: 16000

  # window and hop size in seconds
  N_s: 0.025
  hop_s: 0.010

  # time size in seconds
  frame_size_s: 0.5

  # frame size of output features -> input to nn
  #frame_size: 32
  frame_size: 50

  # number of filter bands and cepstral coeffs for mfcc
  n_filter_bands: 32
  n_ceps_coeff: 12

  # normalized features -> [0, 1] over frames
  norm_features: True

  # old ones do not use anymore: #compute_deltas: True #compute_energy_features: True

  # use deltas as own channels
  use_channels: False

  # feature collection
  use_cepstral_features: True
  use_delta_features: False
  use_double_delta_features: False
  use_energy_features: False


# --
# machine learning settings

ml:

  # paths
  paths:
    log: ignore/logs/
    model: ignore/models/ 
    model_pre: ignore/models/pre/

  # folders in model path
  model_path_folders:
    conv_plots: conv_plots/
    conv_diff_plots: conv_plots/diff_plots/
    train_collections: train_collections/

  # file names
  model_file_name: model.pth
  params_file_name: params.npz
  metrics_file_name: metrics.npz
  info_file_name: info.txt
  score_file_name: info_score.txt

  # encoder model file name
  encoder_model_file_name: encoder_model.pth
  decoder_model_file_name: decoder_model.pth

  # use a pre trained model at pre trained model path
  load_pre_model: False

  # saves the model as pre trained model
  save_as_pre_model: False

  # params
  train_params:

    # batch size
    batch_size: 32
    #batch_size: 64
    #batch_size: 128
    #batch_size: 512

    # number of epochs
    num_epochs: 200

    # learning rate
    lr: 0.0001

    # momentum
    beta: 0.5

  # conv coder folders
  #conv_folder: 'conv_coder/'
  conv_folder: '../conv_coder/'

  # adversarial parameters
  adv_params:

    # train each label with adv
    label_train: False

    # adv pre-training of full network
    pre_train: False

    # use decoder weights for further training
    use_decoder_weights: True

    # label epochs
    num_epochs_label: 1000

    # pre epochs
    num_epochs_pre: 1000

    # iterating algorithm of label: num_iterations_label x num_epochs_label
    num_iterations_label: 1

    # archs for label train:
    #nn_archs_label: ['conv-experimental', 'adv-experimental']
    #nn_archs_label: ['conv-experimental']
    #nn_archs_label: ['adv-experimental']
    #nn_archs_label: ['conv-experimental', 'adv-experimental3']
    #nn_archs_label: ['adv-experimental3', 'conv-experimental']
    nn_archs_label: ['adv-experimental3']

    # normalize label weights
    norm_label_weights: False

  # retrain existing model
  #retrain: True
  retrain: False

  # nn architecture available
  nn_architectures: {1: 'conv-trad', 2: 'conv-fstride', 3: 'adv-experimental', 4: 'conv-experimental', 5: 'conv-encoder'}

  # choose architecture
  #nn_arch: conv-experimental
  #nn_arch: adv-experimental
  #nn_arch: adv-experimental3
  #nn_arch: conv-fstride
  #nn_arch: conv-trad
  #nn_arch: conv-encoder
  #nn_arch: conv-encoder-fc1
  #nn_arch: conv-encoder-fc3
  #nn_arch: conv-lim-encoder
  #nn_arch: conv-latent
  nn_arch: wavenet

  # logging enable
  logging_enabled: True

  # use cpu
  use_cpu: False

  # plot animation
  plot_animation: True

  # plot collections
  plot_collections: True


# --
# test bench

test_bench:

  # plot path
  paths:
    main_path: ignore/test_bench/
    #models_path: ignore/test_bench/test_models/
    shift_wavs: ignore/test_bench/plots/shift_wavs/
    noise_wavs: ignore/test_bench/plots/noise_wavs/

  # enable plot (wav plots -> make it slow)
  enable_plot: False

  # info prints
  enable_info_prints: False

  # test wavs
  test_wavs:
    - ignore/my_recordings/clean_records/left.wav
    - ignore/my_recordings/clean_records/right.wav
    - ignore/my_recordings/clean_records/up.wav
    - ignore/my_recordings/clean_records/down.wav
    - ignore/my_recordings/clean_records/go.wav

  # file names
  model_file_names: ['cnn_model.pth', 'wav_model.pth']
  params_file_name: 'params.npz'

  # snrs
  snrs: [16, 13, 10, 6, 3, 0, -3, -6, -10, -13, -16]

  # shift frames by steps
  shift_frame_step: 1


# --
# classifier

classifier:

  # path to model
  model_path: 'models/conv-fstride/v3_c-5_n-2000/bs-32_it-1000_lr-1e-05/'
  #model_path: 'models/conv-encoder/v4_c-5_n-500_f-13x50/bs-32_it-1024_lr-0p0001/'

  # file names
  model_file_name: 'model.pth'
  params_file_name: 'params.npz'

  # verbose
  verbose: False


# --
# microphone parameters

mic_params:

  # slect specific device
  select_device: False

  # sel device id
  device: 0

  # sampling frequency of your microphone device (idealy this would be 16000, as it will be downsampled to it)
  fs_device: 48000

  # channels to be recorded
  channels: 1

  # energy threshold for onsets
  energy_thresh: 0.0001

  # collector update size (pre frames)
  update_size: 32

  # collector post frames (after onset detection)
  frames_post: 32

  # plot of mic
  plot_path: 'ignore/mic/'

  # enable plot (set false when playing, just for debugging)
  enable_plot: False


# --
# game settings

game:

  # frames per seconds
  fps: 60

  # size of display
  screen_size: [640, 480]

  # enabled flag
  capture_enabled: False

  # capture path
  paths:
    capture_path: ignore/capture/
    frame_path: ignore/capture/frames/

  # user settings file
  user_setting_file: user_settings_game.yaml




