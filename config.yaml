# --
# config file for this project


# --
# dataset config
datasets:

  # speech commands dataset
  speech_commands:

    # file extension for audio files
    file_ext: '.wav'

    # path to speech command dataset
    dataset_path: ./ignore/dataset/speech_commands_v0.01/

    # paths to save training, testing and eval data
    data_paths:
      train: ./ignore/dataset/train/
      test: ./ignore/dataset/test/
      eval: ./ignore/dataset/eval/

    # wav folder name
    wav_folder: wavs/

    # split of dataset in training, test, eval (must be a prob. distribution)
    split_percs: [0.8, 0.1, 0.1]

    # plot path root
    plot_paths:
      mfcc: ./ignore/dataset/plots/mfcc/
      z_score: ./ignore/dataset/plots/z_score/

    # enable plot of each feature extraction
    enable_plot: False

    # recreate all datasets (copy wavs to data_paths - not necessary except the dataset is changed)
    recreate: False

    # selected labels of the whole set
    sel_labels: ['left', 'right', 'up', 'down', 'go']
    #sel_labels = ['eight', 'sheila', 'nine', 'yes', 'one', 'no', 'left', 'tree', 'bed', 'bird', 'go', 'wow', 'seven', 'marvin', 'dog', 'three', 'two', 'house', 'down', 'six', 'five', 'off', 'right', 'cat', 'zero', 'four', 'stop', 'up', 'on', 'happy']

    # --
    # version
    # 1: better onset detection
    # 2: energy frame onset detection
    # 3: data extraction with min energy and randomize onsets
    # 4: normalized features
    version_nr: 4

    # number of examples picked from dataset
    #n_examples: 10
    n_examples: 500

    # file name for saved feature files
    feature_file_name: mfcc_data


  # my recordings dataset
  my_recordings:

    # file extension for audio files
    file_ext: '.wav'

    # path to speech command dataset
    dataset_path: ./ignore/my_recordings/raw/

    # paths to save training, testing and eval data
    data_paths:
      my: ./ignore/my_recordings/my/

    # wav folder name
    wav_folder: wavs/

    # split of dataset
    split_percs: [1.0]

    # plot path root
    plot_paths:
      mfcc: ./ignore/my_recordings/plots/mfcc/
      z_score: ./ignore/my_recordings/plots/z_score/
      onsets: ./ignore/my_recordings/plots/onsets/
      waveform: ./ignore/my_recordings/plots/waveform/

    # enable plot of each feature extraction
    enable_plot: False

    # recreate all datasets (copy wavs to data_paths - not necessary except the dataset is changed)
    recreate: False

    # selected labels of the whole set
    sel_labels: ['left', 'right', 'up', 'down', 'go']
    #sel_labels = ['eight', 'sheila', 'nine', 'yes', 'one', 'no', 'left', 'tree', 'bed', 'bird', 'go', 'wow', 'seven', 'marvin', 'dog', 'three', 'two', 'house', 'down', 'six', 'five', 'off', 'right', 'cat', 'zero', 'four', 'stop', 'up', 'on', 'happy']

    # --
    # version
    # 1: better onset detection
    # 2: energy frame onset detection
    # 3: data extraction with min energy and randomize onsets
    # 4: normalized features
    version_nr: 4

    # number of examples picked from dataset
    n_examples: 5

    # file name for saved feature files
    feature_file_name: mfcc_data_my


    # paths
    out_path_root: ./ignore/my_recordings/
    #in_path: ./ignore/my_recordings/raw/
    #plot_path: ./ignore/my_recordings/plots/
    wav_path: ./ignore/my_recordings/wavs/

    # my recordins set name
    #set_name: 'my'


# --
# feature params for dataset extraction
feature_params:

  # sampling rate
  fs: 16000

  # window and hop size [sec]
  N_s: 0.025
  hop_s: 0.010

  # number of filter bands and cepstral coeffs
  n_filter_bands: 32
  n_ceps_coeff: 12

  # frame size of output features -> input to nn
  frame_size: 32

  # mfcc feat size - do not change this
  feature_size: 39

  # normalized features -> [0, 1] over frames
  norm_features: True


# --
# machine learning settings
ml:

  # paths
  paths:
    log: ./ignore/logs/
    model: ./ignore/models/ 
    model_pre: ./ignore/models/pre/

  # file names
  model_file_name: model.pth
  params_file_name: params.npz
  metrics_file_name: metrics.npz

  # adversarial model file names
  adv_G_model_file_name: g_model.pth
  adv_D_model_file_name: d_model.pth

  # use a pre trained model at pre trained model path
  load_pre_model: True

  # saves the model as pre trained model
  save_as_pre_model: True

  # params
  train_params:

    # batch size
    batch_size: 32

    # number of epochs
    num_epochs: 10

    # learning rate
    lr: 0.0001

    # momentum
    beta: 0.5

  # retrain existing model
  retrain: True

  # nn architecture available
  nn_architectures: {1: 'conv-trad', 2: 'conv-fstride', 3: 'adv-experimental'}

  # chosen architecture
  nn_arch: conv-fstride
  #nn_arch: adv-experimental

  # logging enable
  logging_enabled: True

  # use cpu
  use_cpu: False


# --
# classifier
classifier:

  # path to model
  model_path: './models/conv-fstride/v3_c-5_n-2000/bs-32_it-1000_lr-1e-05/'
  model_file_name: 'model.pth'
  params_file_name: 'params.npz'

  # verbose
  verbose: False


# --
# microphone parameters
mic_params:

  # slect specific device
  select_device: True

  # sel device id
  device: 10

  # sampling frequency of your microphone device (idealy this would be 16000, as it will be downsampled to it)
  fs_device: 48000

  # channels to be recorded
  channels: 1

  # energy threshold for onsets
  energy_thres: 0.0001

  # collector update size (pre frames)
  update_size: 32

  # collector post frames (after onset detection)
  frames_post: 32

  # plot of mic
  plot_path: './ignore/mic/'

  # enable plot (set false when playing, just for debugging)
  enable_plot: False


# --
# game settings
game:

  # frames per seconds
  fps: 60

  # size of display
  screen_size: [640, 480]

  # enabled flag
  capture_enabled: False

  # capture path
  capture_path: ./ignore/capture/




