# --
# config file for this project


# --
# audio dataset config
audio_dataset:

  # path to speech command dataset
  dataset_path: ./ignore/dataset/speech_commands_v0.01/

  # paths to save training, testing and eval data
  data_paths:
    train: ./ignore/dataset/train/
    test: ./ignore/dataset/test/
    eval: ./ignore/dataset/eval/

  # wav folder name
  wav_folder: wavs/

  # plot path root
  plot_paths:
    mfcc: ./ignore/plots/features/mfcc/
    z_score: ./ignore/plots/features/z_score/

  # enable plot of each feature extraction
  enable_plot: False

  # recreate all datasets (copy wavs to data_paths)
  recreate: False

  # split of dataset in training, test, eval (must be a prob. distribution)
  data_percs: [0.8, 0.1, 0.1]

  # selected labels of the whole set
  sel_labels: ['left', 'right', 'up', 'down', 'go']
  #sel_labels = ['eight', 'sheila', 'nine', 'yes', 'one', 'no', 'left', 'tree', 'bed', 'bird', 'go', 'wow', 'seven', 'marvin', 'dog', 'three', 'two', 'house', 'down', 'six', 'five', 'off', 'right', 'cat', 'zero', 'four', 'stop', 'up', 'on', 'happy']

  # --
  # version
  # 1: better onset detection
  # 2: energy frame onset detection
  # 3: data extraction with min energy and randomize onsets
  version_nr: 3

  # number of examples picked from dataset
  #n_examples: 10
  n_examples: 500

  # file name for saved feature files
  mfcc_file_name: mfcc_data


# --
# feature params
feature_params:

  # sampling rate
  fs: 16000

  # window and hop size [sec]
  N_s: 0.025
  hop_s: 0.010

  # number of filter bands and cepstral coeffs
  n_filter_bands: 32
  n_ceps_coeff: 12

  # frame size of output features -> input to nn
  frame_size: 32

  # mfcc feat size - do not change this
  feature_size: 39


# --
# my recording stuff
my_recordings:

  # paths
  out_path_root: ./ignore/my_recordings/
  in_path: ./ignore/my_recordings/raw/
  plot_path: ./ignore/my_recordings/plots/
  wav_path: ./ignore/my_recordings/wavs/

  # my recordins set name
  set_name: 'my'

  # mfcc data file name
  mfcc_file_name: mfcc_data_my

  # enable plot
  enable_plot: False

  # force recut of recordings
  recut: False

  # number of examples per class
  n_examples: 5

  # selected labels for own recordings
  sel_labels: ['left', 'right', 'up', 'down', 'go']


# --
# machine learning settings
ml:

  # paths
  paths:
    log: ./ignore/logs/
    model: ./ignore/models/ 
    model_pre: ./ignore/models/pre/

  # file names
  model_file_name: model.pth
  params_file_name: params.npz
  metrics_file_name: metrics.npz

  # use a pre trained model at pre trained model path
  load_pre_model: True

  # saves the model as pre trained model
  save_as_pre_model: True

  # params
  train_params:

    # batch size
    batch_size: 32

    # number of epochs
    num_epochs: 10

    # learning rate
    lr: 0.0001

  # retrain existing model
  retrain: True

  # nn architecture available
  nn_architectures: {1: 'conv-trad', 2: 'conv-fstride'}

  # chosen architecture
  nn_arch: conv-fstride

  # logging enable
  logging_enabled: True


# --
# classifier
classifier:

  # path to model
  model_path: './models/conv-fstride/v3_c-5_n-2000/bs-32_it-1000_lr-1e-05/'

  # verbose
  verbose: False


# --
# game settings
game:

  # frames per seconds
  fps: 60

  # size of display
  screen_size: [640, 480]

  # enabled flag
  capture_enabled: False

  # capture path
  capture_path: ./ignore/capture/




